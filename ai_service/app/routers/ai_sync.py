import logging
import httpx
from fastapi import APIRouter, Depends, HTTPException, Query
from app.services.vector_store import VectorStoreService
from typing import Optional
import os

log = logging.getLogger(__name__)

sync_router = APIRouter(
    prefix="/sync",
    tags=["AI / Data Sync"]
)

def get_vector_store_service():
    from app.routers import vector_store_service
    return vector_store_service

# Backend Node.js URL - c√≥ th·ªÉ config trong .env
BACKEND_URL = os.getenv("BACKEND_URL", "http://127.0.0.1:3000")

@sync_router.post("/tasks-from-backend")
async def sync_tasks_from_backend(
    page_limit: int = Query(default=100, description="S·ªë l∆∞·ª£ng tasks m·ªói page"),
    max_pages: Optional[int] = Query(default=None, description="Gi·ªõi h·∫°n s·ªë pages (None = sync all)"),
    force: bool = Query(default=True, description="Force upsert (x√≥a b·∫£n c≈© tr∆∞·ªõc khi insert)"),
    vector_store_svc: VectorStoreService = Depends(get_vector_store_service)
):
    """
    Sync tasks t·ª´ backend Node.js v√†o AI service vector store.
    
    Flow:
    1. G·ªçi API /aidata/tasks v·ªõi pagination t·ª´ backend Node.js
    2. V·ªõi m·ªói task, upsert v√†o vector store
    3. Ti·∫øp t·ª•c cho ƒë·∫øn khi h·∫øt data ho·∫∑c ƒë·∫°t max_pages
    
    Args:
        page_limit: S·ªë tasks m·ªói l·∫ßn fetch (default: 100)
        max_pages: Gi·ªõi h·∫°n s·ªë pages (None = sync t·∫•t c·∫£)
        force: X√≥a task c≈© tr∆∞·ªõc khi insert (default: True)
    
    Returns:
        Th·ªëng k√™ sync: total, success, failed, errors
    """
    
    results = {
        "total_fetched": 0,
        "total_synced": 0,
        "total_failed": 0,
        "pages_processed": 0,
        "errors": []
    }
    
    current_page = 1
    has_more = True
    
    async with httpx.AsyncClient(timeout=30.0) as client:
        while has_more:
            # Ki·ªÉm tra gi·ªõi h·∫°n pages
            if max_pages and current_page > max_pages:
                log.info(f"‚èπÔ∏è  Reached max_pages limit: {max_pages}")
                break
            
            try:
                # G·ªçi API backend ƒë·ªÉ l·∫•y tasks
                response = await client.get(
                    f"{BACKEND_URL}/api/aidata/tasks",
                    params={
                        "page": current_page,
                        "limit": page_limit
                    }
                )
                
                # Parse response JSON
                response_data = response.json()
                
                # Ki·ªÉm tra status code
                if response_data.get("code") != 200:
                    error_msg = f"Backend API returned code {response_data.get('code')}"
                    results["errors"].append({
                        "page": current_page,
                        "error": error_msg,
                        "response": str(response_data)[:200]
                    })
                    break
                
                # L·∫•y metadata
                metadata = response_data.get("metadata", {})
                tasks = metadata.get("tasks", [])
                page_info = metadata.get("page", {})
                total_available = page_info.get("total", 0)
                
                # Fallback: n·∫øu kh√¥ng c√≥ metadata, th·ª≠ format c≈©
                if not tasks and isinstance(response_data, list):
                    tasks = response_data
                    total_available = len(tasks)
                
                if not tasks or len(tasks) == 0:
                    log.info(f"‚úÖ No more tasks on page {current_page}. Sync complete!")
                    has_more = False
                    break
                
                log.info(f"üì¶ Received {len(tasks)} tasks from page {current_page}")
                results["total_fetched"] += len(tasks)
                results["pages_processed"] = current_page
                
                # Sync t·ª´ng task v√†o vector store
                for idx, task in enumerate(tasks, 1):
                    try:
                        # Chu·∫©n b·ªã task data
                        task_data = {
                            "id": str(task.get("id")),
                            "title": task.get("title", ""),
                            "description": task.get("description", ""),
                            "status": task.get("status", ""),
                            "dueDate": task.get("dueDate"),
                            "estimateEffort": task.get("estimateEffort"),
                            "actualEffort": task.get("actualEffort"),
                            "implementorId": str(task.get("assigneeId")) if task.get("assigneeId") else None,
                            "reviewerId": str(task.get("reviewerId")) if task.get("reviewerId") else None,
                            "projectId": str(task.get("projectId")) if task.get("projectId") else None,
                            "priority": task.get("priority", "MEDIUM"),
                            "completedAt": task.get("completedAt"),
                            "type": task.get("type"),
                            "score": task.get("score")  # Quality score
                        }
                        
                        # Upsert v√†o vector store
                        success = vector_store_svc.upsert_task(task=task_data, force=force)
                        
                        if success:
                            results["total_synced"] += 1
                            if idx % 10 == 0:
                                log.info(f"   ‚úì Synced {idx}/{len(tasks)} tasks from page {current_page}")
                        else:
                            results["total_failed"] += 1
                            results["errors"].append({
                                "task_id": task_data["id"],
                                "title": task_data["title"],
                                "error": "upsert_task returned False"
                            })
                            
                    except Exception as e:
                        results["total_failed"] += 1
                        results["errors"].append({
                            "task_id": task.get("id", "unknown"),
                            "title": task.get("title", "unknown"),
                            "error": str(e)
                        })
                        log.error(f"   ‚ùå Failed to sync task {task.get('id')}: {str(e)}")
                
                log.info(f"‚úÖ Page {current_page} completed: {results['total_synced']}/{results['total_fetched']} synced")
                
                # Ki·ªÉm tra xem c√≤n data kh√¥ng
                if len(tasks) < page_limit:
                    log.info(f"‚úÖ Received less than {page_limit} tasks. No more data!")
                    has_more = False
                else:
                    current_page += 1
                    
            except httpx.TimeoutException:
                error_msg = f"Timeout when fetching page {current_page}"
                log.error(f"‚ùå {error_msg}")
                results["errors"].append({
                    "page": current_page,
                    "error": error_msg
                })
                break
                
            except Exception as e:
                error_msg = f"Error on page {current_page}: {str(e)}"
                log.error(f"‚ùå {error_msg}")
                results["errors"].append({
                    "page": current_page,
                    "error": error_msg
                })
                break
    
    # Summary
    log.info("=" * 70)
    log.info("üìä SYNC SUMMARY")
    log.info("=" * 70)
    log.info(f"Total fetched: {results['total_fetched']}")
    log.info(f"Total synced: {results['total_synced']}")
    log.info(f"Total failed: {results['total_failed']}")
    log.info(f"Pages processed: {results['pages_processed']}")
    log.info(f"Errors: {len(results['errors'])}")
    log.info("=" * 70)
    
    return {
        "success": True,
        "message": f"Synced {results['total_synced']}/{results['total_fetched']} tasks from {results['pages_processed']} pages",
        "stats": results
    }


@sync_router.get("/status")
async def get_sync_status(
    vector_store_svc: VectorStoreService = Depends(get_vector_store_service)
):
    """
    Ki·ªÉm tra s·ªë l∆∞·ª£ng tasks hi·ªán c√≥ trong vector store.
    """
    # Note: C·∫ßn implement method count_tasks() trong VectorStoreService
    # T·∫°m th·ªùi return placeholder
    return {
        "backend_url": BACKEND_URL,
        "vector_store": "ChromaDB",
        "status": "ready",
        "message": "Use POST /sync/tasks-from-backend to sync data"
    }
